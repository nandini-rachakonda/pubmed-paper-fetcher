{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TlOaCWjPbLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NPHCLDypOxbo"
      },
      "outputs": [],
      "source": [
        "# pubmed_fetcher/module.py\n",
        "import csv\n",
        "import logging\n",
        "import re\n",
        "import time\n",
        "from typing import List, Dict\n",
        "import xml.etree.ElementTree as ET\n",
        "import requests\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Keywords for filtering affiliations\n",
        "ACADEMIC_TERMS = [\"university\", \"college\", \"institute\", \"school\", \"faculty\", \"department\", \"center\"]\n",
        "CORPORATE_TERMS = [\"pharma\", \"biotech\", \"therapeutics\", \"laboratories\", \"inc\", \"corp\", \"llc\", \"gmbh\", \"ltd\"]\n",
        "\n",
        "def affiliation_is_academic(affiliation: str) -> bool:\n",
        "    lower_aff = affiliation.lower()\n",
        "    return any(term in lower_aff for term in ACADEMIC_TERMS)\n",
        "\n",
        "def affiliation_is_corporate(affiliation: str) -> bool:\n",
        "    lower_aff = affiliation.lower()\n",
        "    return any(term in lower_aff for term in CORPORATE_TERMS)\n",
        "\n",
        "def get_pubmed_ids(query: str) -> List[str]:\n",
        "    search_endpoint = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "    parameters = {\"db\": \"pubmed\", \"term\": query, \"retmode\": \"json\", \"retmax\": 100}\n",
        "    response = requests.get(search_endpoint, params=parameters)\n",
        "    response.raise_for_status()\n",
        "    return response.json().get(\"esearchresult\", {}).get(\"idlist\", [])\n",
        "\n",
        "def retrieve_paper_details(pubmed_id: str) -> Dict[str, str]:\n",
        "    fetch_endpoint = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "    parameters = {\"db\": \"pubmed\", \"id\": pubmed_id, \"retmode\": \"xml\"}\n",
        "    response = requests.get(fetch_endpoint, params=parameters)\n",
        "    response.raise_for_status()\n",
        "    tree = ET.fromstring(response.text)\n",
        "    article = tree.find(\".//PubmedArticle\")\n",
        "    return extract_metadata(article)\n",
        "\n",
        "def extract_metadata(article) -> Dict[str, str]:\n",
        "    title = article.findtext(\".//ArticleTitle\", default=\"\")\n",
        "    pub_date = article.findtext(\".//PubDate/Year\", default=\"\")\n",
        "    authors = article.findall(\".//Author\")\n",
        "\n",
        "    corporate_authors = []\n",
        "    company_names = set()\n",
        "    contact_email = \"\"\n",
        "\n",
        "    for person in authors:\n",
        "        affiliation = person.findtext(\"AffiliationInfo/Affiliation\", default=\"\")\n",
        "        last = person.findtext(\"LastName\", default=\"\")\n",
        "        first = person.findtext(\"ForeName\", default=\"\")\n",
        "        name = f\"{last}, {first}\"\n",
        "\n",
        "        email_found = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\", affiliation)\n",
        "        if email_found:\n",
        "            contact_email = email_found.group()\n",
        "\n",
        "        if affiliation and not affiliation_is_academic(affiliation) and affiliation_is_corporate(affiliation):\n",
        "            corporate_authors.append(name)\n",
        "            company_names.add(affiliation)\n",
        "\n",
        "    return {\n",
        "        \"PubmedID\": article.findtext(\"MedlineCitation/PMID\", default=\"\"),\n",
        "        \"Title\": title,\n",
        "        \"Publication Date\": pub_date,\n",
        "        \"Non-academic Author(s)\": \"; \".join(corporate_authors),\n",
        "        \"Company Affiliation(s)\": \"; \".join(company_names),\n",
        "        \"Corresponding Author Email\": contact_email,\n",
        "    }\n",
        "\n",
        "def gather_papers(query: str, debug: bool = False) -> List[Dict[str, str]]:\n",
        "    if debug:\n",
        "        logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "    ids = get_pubmed_ids(query)\n",
        "    logger.debug(f\"Total PubMed IDs fetched: {len(ids)}\")\n",
        "    results = []\n",
        "\n",
        "    for index, pid in enumerate(ids):\n",
        "        logger.debug(f\"Processing PubMed ID {pid} ({index + 1} of {len(ids)})\")\n",
        "        try:\n",
        "            info = retrieve_paper_details(pid)\n",
        "            if info[\"Non-academic Author(s)\"]:\n",
        "                results.append(info)\n",
        "        except Exception as err:\n",
        "            logger.error(f\"Failed to process ID {pid}: {err}\")\n",
        "        time.sleep(0.3)\n",
        "\n",
        "    return results\n",
        "\n",
        "def export_to_csv(filepath: str, records: List[Dict[str, str]]) -> None:\n",
        "    with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as output:\n",
        "        writer = csv.DictWriter(output, fieldnames=records[0].keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerows(records)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = \"COVID-19 vaccine\"  # Change this to your topic\n",
        "results = gather_papers(query, debug=True)\n",
        "\n",
        "if results:\n",
        "    csv_filename = \"pubmed_results.csv\"\n",
        "    export_to_csv(csv_filename, results)\n",
        "    print(f\"✅ CSV generated: {csv_filename} with {len(results)} records\")\n",
        "else:\n",
        "    print(\"❌ No corporate-affiliated authors found in the query.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8_V2YsKPfhz",
        "outputId": "8ad40a4d-9207-419b-d72c-780950ff18be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV generated: pubmed_results.csv with 6 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"pubmed_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RoIxaeROQsfm",
        "outputId": "8d014885-a160-4402-8228-cc4b22e1bd90"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_47a18ce0-87ef-481b-8482-2103d1333848\", \"pubmed_results.csv\", 2397)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}